{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# imports\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import kaggle\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# paths\n",
    "tmp_path = 'tmp'\n",
    "train_dataset_path = f'{tmp_path}/train_dataset'\n",
    "test_dataset_path = f'{tmp_path}/test_dataset'\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# download dataset\n",
    "if not os.path.exists(train_dataset_path) or not os.path.exists(test_dataset_path):\n",
    "    kaggle.api.authenticate()\n",
    "    kaggle.api.dataset_download_files('grassknoted/asl-alphabet', path=tmp_path, unzip=True)\n",
    "\n",
    "    shutil.move(f\"{tmp_path}/asl_alphabet_train/asl_alphabet_train\", train_dataset_path)\n",
    "    shutil.move(f\"{tmp_path}/asl_alphabet_test/asl_alphabet_test\", test_dataset_path)\n",
    "\n",
    "    shutil.rmtree(f\"{tmp_path}/asl_alphabet_train\")\n",
    "    shutil.rmtree(f\"{tmp_path}/asl_alphabet_test\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PyTorch device\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=train_dataset_path, transform=transform)\n",
    "dataset\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get classes\n",
    "classes = dataset.classes\n",
    "classes\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count classes\n",
    "classes_count = len(classes)\n",
    "classes_count\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set train/test split ratio\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "{\"train_ratio\": train_ratio, \"test_ratio\": test_ratio}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set train/test sizes\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = int(test_ratio * len(dataset))\n",
    "{\"train_size\": train_size, \"test_size\": test_size}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Split dataset into train and test\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Count train/test dataset sizes\n",
    "train_dataset_count = len(train_dataset)\n",
    "test_dataset_count = len(test_dataset)\n",
    "{\"train_dataset_count\": train_dataset_count, \"test_dataset_count\": test_dataset_count}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display random images function\n",
    "def show_random_samples(dataset, classes, num_samples=5):\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(15, 15))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        index = np.random.randint(0, len(dataset) - 1)\n",
    "        image, label = dataset[index]\n",
    "\n",
    "        axs[i].imshow(image.permute(1, 2, 0))\n",
    "        axs[i].set_title(classes[label])\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display random images from train dataset\n",
    "show_random_samples(train_dataset, classes)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display random images from test dataset\n",
    "show_random_samples(test_dataset, classes)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare models\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Make models folder"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.makedirs('tmp/models', exist_ok=True)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Make model losses folder\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.makedirs('tmp/model_losses', exist_ok=True)\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "AlexNet_model = models.alexnet()\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in AlexNet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to fit your number of classes\n",
    "AlexNet_model.classifier[6] = torch.nn.Linear(AlexNet_model.classifier[6].in_features, classes_count)\n",
    "\n",
    "# Move the model to the device (GPU if available)\n",
    "AlexNet_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "AlexNet_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "AlexNet_model_optimizer = torch.optim.Adam(AlexNet_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary(AlexNet_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "GoogleNet_model = models.googlenet(models.GoogLeNet_Weights.DEFAULT)\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in GoogleNet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to fit your number of classes\n",
    "GoogleNet_model.fc = torch.nn.Linear(GoogleNet_model.fc.in_features, classes_count)\n",
    "\n",
    "# Move the model to the device (GPU if available)\n",
    "GoogleNet_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "GoogleNet_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "GoogleNet_model_optimizer = torch.optim.Adam(GoogleNet_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary(GoogleNet_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V2\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MobileNetV2_model = models.MobileNetV2()\n",
    "\n",
    "# # Freeze model parameters\n",
    "# for param in MobileNetV2_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Modify the last fully connected layer to fit your number of classes\n",
    "# MobileNetV2_model.classifier[6] = torch.nn.Linear(MobileNetV2_model.classifier[6].in_features, classes_count)\n",
    "\n",
    "# # Move the model to the device (GPU if available)\n",
    "# MobileNetV2_model.to(device)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# MobileNetV2_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "# MobileNetV2_model_optimizer = torch.optim.Adam(MobileNetV2_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# summary(MobileNetV2_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V3\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MobileNetV3_model = models.MobileNetV3()\n",
    "\n",
    "# # Freeze model parameters\n",
    "# for param in MobileNetV3_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Modify the last fully connected layer to fit your number of classes\n",
    "# MobileNetV3_model.classifier[6] = torch.nn.Linear(MobileNetV3_model.classifier[6].in_features, classes_count)\n",
    "\n",
    "# # Move the model to the device (GPU if available)\n",
    "# MobileNetV3_model.to(device)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# MobileNetV3_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "# MobileNetV3_model_optimizer = torch.optim.Adam(MobileNetV3_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# summary(MobileNetV3_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 18\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ResNet18_model = models.resnet18()\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in ResNet18_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to fit your number of classes\n",
    "ResNet18_model.fc = torch.nn.Linear(ResNet18_model.fc.in_features, classes_count)\n",
    "\n",
    "# Move the model to the device (GPU if available)\n",
    "ResNet18_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "ResNet18_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "ResNet18_model_optimizer = torch.optim.Adam(ResNet18_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary(ResNet18_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ResNet50_model = models.resnet50()\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in ResNet50_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to fit your number of classes\n",
    "ResNet50_model.fc = torch.nn.Linear(ResNet50_model.fc.in_features, classes_count)\n",
    "\n",
    "# Move the model to the device (GPU if available)\n",
    "ResNet50_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "ResNet50_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "ResNet50_model_optimizer = torch.optim.Adam(ResNet50_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary(ResNet50_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg16\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Vgg16_model = models.vgg16()\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in Vgg16_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to fit your number of classes\n",
    "Vgg16_model.classifier[6] = torch.nn.Linear(Vgg16_model.classifier[6].in_features, classes_count)\n",
    "\n",
    "# Move the model to the device (GPU if available)\n",
    "Vgg16_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "Vgg16_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "Vgg16_model_optimizer = torch.optim.Adam(Vgg16_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary(Vgg16_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg19\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Vgg19_model = models.vgg16()\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in Vgg19_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to fit your number of classes\n",
    "Vgg19_model.classifier[6] = torch.nn.Linear(Vgg19_model.classifier[6].in_features, classes_count)\n",
    "\n",
    "# Move the model to the device (GPU if available)\n",
    "Vgg19_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "Vgg19_model_criterion = torch.nn.CrossEntropyLoss()\n",
    "Vgg19_model_optimizer = torch.optim.Adam(Vgg19_model.parameters(), lr=0.001)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary(Vgg19_model, input_size=(3, 200, 200))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# train model function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    epochs_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epochs_losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    return epochs_losses\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "AlexNet_model_losses = None\n",
    "model_path = 'tmp/models/ASL_AlexNet_model_V1.0.0.pth'\n",
    "model_losses_path = 'tmp/model_losses/ASL_AlexNet_model_losses_V1.0.0.json'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    AlexNet_model = torch.load(model_path)\n",
    "\n",
    "    with open(model_losses_path) as filehandle:\n",
    "        AlexNet_model_losses = json.load(filehandle)\n",
    "else:\n",
    "    AlexNet_model_losses = train_model(AlexNet_model, train_loader, AlexNet_model_criterion, AlexNet_model_optimizer, device, num_epochs=10)\n",
    "    torch.save(AlexNet_model, model_path)\n",
    "\n",
    "    with open(model_losses_path, 'w') as filehandle:\n",
    "        json.dump(AlexNet_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "AlexNet_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "GoogleNet_model_losses = None\n",
    "model_path = 'tmp/models/ASL_GoogleNet_model_V1.0.0.pth'\n",
    "model_losses_path = 'tmp/model_losses/ASL_GoogleNet_model_losses_V1.0.0.json'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    GoogleNet_model = torch.load(model_path)\n",
    "\n",
    "    with open(model_losses_path) as filehandle:\n",
    "        GoogleNet_model_losses = json.load(filehandle)\n",
    "else:\n",
    "    GoogleNet_model_losses = train_model(GoogleNet_model, train_loader, GoogleNet_model_criterion, GoogleNet_model_optimizer, device, num_epochs=10)\n",
    "    torch.save(GoogleNet_model, model_path)\n",
    "\n",
    "    with open(model_losses_path, 'w') as filehandle:\n",
    "        json.dump(GoogleNet_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "GoogleNet_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V2\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MobileNetV2_model_losses = None\n",
    "# model_path = 'tmp/models/ASL_MobileNetV2_model_V1.0.0.pth'\n",
    "# model_losses_path = 'tmp/model_losses/ASL_MobileNetV2_model_losses_V1.0.0.json'\n",
    "# \n",
    "# if os.path.isfile(model_path):\n",
    "#     MobileNetV2_model = torch.load(model_path)\n",
    "# \n",
    "#     with open(model_losses_path) as filehandle:\n",
    "#         MobileNetV2_model_losses = json.load(filehandle)\n",
    "# else:\n",
    "#     MobileNetV2_model_losses = train_model(MobileNetV2_model, train_loader, MobileNetV2_model_criterion, MobileNetV2_model_optimizer, device, num_epochs=10)\n",
    "#     torch.save(MobileNetV2_model, model_path)\n",
    "# \n",
    "#     with open(model_losses_path, 'w') as filehandle:\n",
    "#         json.dump(MobileNetV2_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# MobileNetV2_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### MobileNet V3\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MobileNetV3_model_losses = None\n",
    "# model_path = 'tmp/models/ASL_MobileNetV3_model_V1.0.0.pth'\n",
    "# model_losses_path = 'tmp/model_losses/ASL_MobileNetV3_model_losses_V1.0.0.json'\n",
    "# \n",
    "# if os.path.isfile(model_path):\n",
    "#     MobileNetV3_model = torch.load(model_path)\n",
    "# \n",
    "#     with open(model_losses_path) as filehandle:\n",
    "#         MobileNetV3_model_losses = json.load(filehandle)\n",
    "# else:\n",
    "#     MobileNetV3_model_losses = train_model(MobileNetV3_model, train_loader, MobileNetV3_model_criterion, MobileNetV3_model_optimizer, device, num_epochs=10)\n",
    "#     torch.save(MobileNetV3_model, model_path)\n",
    "# \n",
    "#     with open(model_losses_path, 'w') as filehandle:\n",
    "#         json.dump(MobileNetV3_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# MobileNetV3_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 18\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ResNet18_model_losses = None\n",
    "model_path = 'tmp/models/ASL_ResNet18_model_V1.0.0.pth'\n",
    "model_losses_path = 'tmp/model_losses/ASL_ResNet18_model_losses_V1.0.0.json'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    ResNet18_model = torch.load(model_path)\n",
    "\n",
    "    with open(model_losses_path) as filehandle:\n",
    "        ResNet18_model_losses = json.load(filehandle)\n",
    "else:\n",
    "    ResNet18_model_losses = train_model(ResNet18_model, train_loader, ResNet18_model_criterion, ResNet18_model_optimizer, device, num_epochs=10)\n",
    "    torch.save(ResNet18_model, model_path)\n",
    "\n",
    "    with open(model_losses_path, 'w') as filehandle:\n",
    "        json.dump(ResNet18_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ResNet18_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ResNet50_model_losses = None\n",
    "model_path = 'tmp/models/ASL_ResNet50_model_V1.0.0.pth'\n",
    "model_losses_path = 'tmp/model_losses/ASL_ResNet50_model_losses_V1.0.0.json'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    ResNet50_model = torch.load(model_path)\n",
    "\n",
    "    with open(model_losses_path) as filehandle:\n",
    "        ResNet50_model_losses = json.load(filehandle)\n",
    "else:\n",
    "    ResNet50_model_losses = train_model(ResNet50_model, train_loader, ResNet50_model_criterion, ResNet50_model_optimizer, device, num_epochs=10)\n",
    "    torch.save(ResNet50_model, model_path)\n",
    "\n",
    "    with open(model_losses_path, 'w') as filehandle:\n",
    "        json.dump(ResNet50_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ResNet50_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg16\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Vgg16_model_losses = None\n",
    "model_path = 'tmp/models/ASL_Vgg16_model_V1.0.0.pth'\n",
    "model_losses_path = 'tmp/model_losses/ASL_Vgg16_model_losses_V1.0.0.json'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    Vgg16_model = torch.load(model_path)\n",
    "\n",
    "    with open(model_losses_path) as filehandle:\n",
    "        Vgg16_model_losses = json.load(filehandle)\n",
    "else:\n",
    "    Vgg16_model_losses = train_model(Vgg16_model, train_loader, Vgg16_model_criterion, Vgg16_model_optimizer, device, num_epochs=10)\n",
    "    torch.save(Vgg16_model, model_path)\n",
    "\n",
    "    with open(model_losses_path, 'w') as filehandle:\n",
    "        json.dump(Vgg16_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Vgg16_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg19\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Vgg19_model_losses = None\n",
    "model_path = 'tmp/models/ASL_Vgg19_model_V1.0.0.pth'\n",
    "model_losses_path = 'tmp/model_losses/ASL_Vgg19_model_losses_V1.0.0.json'\n",
    "\n",
    "if os.path.isfile(model_path):\n",
    "    Vgg19_model = torch.load(model_path)\n",
    "\n",
    "    with open(model_losses_path) as filehandle:\n",
    "        Vgg19_model_losses = json.load(filehandle)\n",
    "else:\n",
    "    Vgg19_model_losses = train_model(Vgg19_model, train_loader, Vgg19_model_criterion, Vgg19_model_optimizer, device, num_epochs=10)\n",
    "    torch.save(Vgg19_model, model_path)\n",
    "\n",
    "    with open(model_losses_path, 'w') as filehandle:\n",
    "        json.dump(Vgg19_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Vgg19_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Custom_model_losses = None\n",
    "# model_path = 'tmp/models/ASL_Custom_model_V1.0.0.pth'\n",
    "# model_losses_path = 'tmp/model_losses/ASL_Custom_model_losses_V1.0.0.json'\n",
    "# \n",
    "# if os.path.isfile(model_path):\n",
    "#     Custom_model = torch.load(model_path)\n",
    "# \n",
    "#     with open(model_losses_path) as filehandle:\n",
    "#         Custom_model_losses = json.load(filehandle)\n",
    "# else:\n",
    "#     Custom_model_losses = train_model(Custom_model, train_loader, Custom_model_criterion, Custom_model_optimizer, device, num_epochs=10)\n",
    "#     torch.save(Custom_model, model_path)\n",
    "# \n",
    "#     with open(model_losses_path, 'w') as filehandle:\n",
    "#         json.dump(Custom_model_losses, filehandle)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Custom_model_losses\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Losses plot\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_losses = [\n",
    "    AlexNet_model_losses,\n",
    "    GoogleNet_model_losses,\n",
    "    # MobileNetV2_model_losses,\n",
    "    # MobileNetV3_model_losses,\n",
    "    ResNet18_model_losses,\n",
    "    ResNet50_model_losses,\n",
    "    Vgg16_model_losses,\n",
    "    Vgg19_model_losses,\n",
    "    # Custom_model_losses,\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for losses in all_losses:\n",
    "    plt.plot(losses)\n",
    "plt.title('Model Losses')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\n",
    "    \"AlexNet\",\n",
    "    \"GoogleNet\",\n",
    "    # \"MobileNetV2\",\n",
    "    # \"MobileNetV3\",\n",
    "    \"ResNet18\",\n",
    "    \"ResNet50\",\n",
    "    \"Vgg16\",\n",
    "    \"Vgg19\",\n",
    "    # \"Custom\",\n",
    "])\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test model function\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "AlexNet_model_accuracy = test_model(AlexNet_model, test_loader, AlexNet_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "GoogleNet_model_accuracy = test_model(GoogleNet_model, test_loader, GoogleNet_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V2\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "# MobileNetV2_model_accuracy = test_model(MobileNetV2_model, test_loader, MobileNetV2_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V3\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "# MobileNetV3_model_accuracy = test_model(MobileNetV3_model, test_loader, MobileNetV3_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 18\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "ResNet18_model_accuracy = test_model(ResNet18_model, test_loader, ResNet18_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "ResNet50_model_accuracy = test_model(ResNet50_model, test_loader, ResNet50_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg16\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "Vgg16_model_accuracy = test_model(Vgg16_model, test_loader, Vgg16_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg19\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "Vgg19_model_accuracy = test_model(Vgg19_model, test_loader, Vgg19_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "# Custom_model_accuracy = test_model(Custom_model, test_loader, Custom_model_criterion, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Summary\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a dictionary to store results\n",
    "model_results = {\n",
    "    \"Model\": [\n",
    "        \"AlexNet\",\n",
    "        \"GoogleNet\",\n",
    "        # \"MobileNetV2\",\n",
    "        # \"MobileNetV3\",\n",
    "        \"ResNet18\",\n",
    "        \"ResNet50\",\n",
    "        \"Vgg16\",\n",
    "        \"Vgg19\",\n",
    "        # \"Custom\",\n",
    "    ],\n",
    "    \"Loss\": [\n",
    "        AlexNet_model_losses[-1],\n",
    "        GoogleNet_model_losses[-1],\n",
    "        # MobileNetV2_model_losses[-1],\n",
    "        # MobileNetV3_model_losses[-1],\n",
    "        ResNet18_model_losses[-1],\n",
    "        ResNet50_model_losses[-1],\n",
    "        Vgg16_model_losses[-1],\n",
    "        Vgg19_model_losses[-1],\n",
    "        # Custom_model_losses[-1],\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        AlexNet_model_accuracy,\n",
    "        GoogleNet_model_accuracy,\n",
    "        # MobileNetV2_model_accuracy,\n",
    "        # MobileNetV3_model_accuracy,\n",
    "        ResNet18_model_accuracy,\n",
    "        ResNet50_model_accuracy,\n",
    "        Vgg16_model_accuracy,\n",
    "        Vgg19_model_accuracy,\n",
    "        # Custom_model_accuracy,\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame from the dictionary\n",
    "df = pd.DataFrame(model_results)\n",
    "\n",
    "# Print the DataFrame as a table\n",
    "print(df.to_string())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predict and display image function\n",
    "def predict_and_display_image(model, image_path, transform, device):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Make a prediction\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = classes[predicted.item()]\n",
    "\n",
    "    # Display the image and prediction\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class} - {model.__class__.__name__}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "images_paths = [\n",
    "    'tmp/test_g.jpeg',\n",
    "    'tmp/test_dataset/G_test.jpg',\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_path in images_paths:\n",
    "    predict_and_display_image(AlexNet_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_path in images_paths:\n",
    "    predict_and_display_image(GoogleNet_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V2\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for image_path in images_paths:\n",
    "#     predict_and_display_image(MobileNetV2_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet V3\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for image_path in images_paths:\n",
    "#     predict_and_display_image(MobileNetV3_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 18\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_path in images_paths:\n",
    "    predict_and_display_image(ResNet18_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_path in images_paths:\n",
    "    predict_and_display_image(ResNet50_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg16\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_path in images_paths:\n",
    "    predict_and_display_image(Vgg16_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg19\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for image_path in images_paths:\n",
    "    predict_and_display_image(Vgg19_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for image_path in images_paths:\n",
    "#     predict_and_display_image(Custom_model, image_path, transform, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
